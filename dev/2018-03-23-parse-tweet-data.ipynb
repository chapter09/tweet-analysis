{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import csv\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_file = \"/mnt/tweets/dev-parsed.csv\"\n",
    "cln_file = \"/mnt/tweets/dev-parsed-cleaned.csv\"\n",
    "dict_file = \"\"\n",
    "labeled_file = \"../data/parsed/dev-labeled.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data. Due to the bug of Pandas `to_csv` (https://github.com/pandas-dev/pandas/issues/17365), we have the following lines that `read_csv` cannot correctly parse:\n",
    "\n",
    "```\n",
    "24,135724218678657024,\"Thanking the man above for letting me & my loved ones see another day &lt;3\n",
    "#thankful\"\n",
    "25,148946558874947584,No one wants yogurt on a Monday night. :( #lonely\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(orig_file) as fd:\n",
    "    lines = fd.readlines()\n",
    "    lines_cleaned = []\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    def iter_func(i, lines):\n",
    "        '''\n",
    "        recursively read the next line, stop when the next line starts with a number\n",
    "        '''\n",
    "        \n",
    "        cur_l = lines[i]\n",
    "        if not cur_l[0].isdigit():\n",
    "            lx, pos = iter_func(i+1, lines)\n",
    "            return cur_l.strip()+\" \"+lx, pos\n",
    "        else:\n",
    "            return \"\", i\n",
    "    \n",
    "    while i < len(lines)-1:\n",
    "        if lines[i][0].isdigit() and not lines[i+1][0].isdigit():\n",
    "            cur_l = lines[i]\n",
    "            lx, i = iter_func(i+1, lines)\n",
    "            lines_cleaned.append(cur_l.strip()+\" \"+lx)\n",
    "            continue\n",
    "        elif lines[i][0].isdigit() and lines[i+1][0].isdigit():\n",
    "            lines_cleaned.append(lines[i].strip())\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            '''\n",
    "            Unexpected lines\n",
    "            '''\n",
    "            print(i, lines[i])\n",
    "            break\n",
    "    \n",
    "with open(\"/mnt/tweets/dev-parsed-cleaned.csv\", 'w') as fd:\n",
    "    for line in lines_cleaned:\n",
    "        fd.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dictionary to obtain the labels of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(cln_file, names=['id', 'tid', 'tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(dict_file, delimiter='\\t', names=['t_id', 'emotion'])\n",
    "r_data_dict = raw_data.set_index('t_id').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emotion'] = data['tid'].apply(lambda tid: r_data_dict['emotion'].get(tid, np.NaN))\n",
    "data = data.drop('id', axis=1)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(labeled_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
